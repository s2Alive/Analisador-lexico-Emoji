import re

class AnalisadorLexico:
    # Token linha
    lin_num = 1

    def cria_token(self, code):
        regras = [
            ('INT', r'üî¢'),             # Tipo Inteiro
            ('STR', r'üî¢'),             # Tipo String
            ('BOOL', r'üî¢'),            # Tipo Booleano
            ('TRUE', r'üî¢'),            # Verdadeiro
            ('FALSE', r'üî¢'),           # Falso
            ('IF', r'ü§®'),              # Se
            ('ELSE', r'üò£'),            # Sen√£o
            ('WHILE', r'‚è∞'),           # Enquanto
            ('FOR', r'üòµ'),             # Para
            ('SWITCH', r'üßê'),          # Escolha
            ('CASE', r'üîé'),            # Caso
            ('BREAK', r'üëä'),           # Quebra
            ('CONT', r'üóø'),             # Continua
            ('TRY', r'ü§î'),             # Tente
            ('CATCH', r'‚õî'),           # Pegue
            ('RETURN', r'üîÅ'),          # Retorne
            ('INPUT', r'üìù'),           # Entrada
            ('SLEEP', r'üò¥'),           # Dorme
            ('PRINT', r'üñ®Ô∏è'),           # Imprima
            ('ABRE_PAR', r'\('),        # (
            ('FECHA_PAR', r'\)'),        # )
            ('ABRE_CHAVES', r'\{'),          # {
            ('FECHA_CHAVES', r'\}'),          # }
            ('VIRG', r','),            # ,
            ('P_VIRG', r';'),           # ;
            ('DOIS_PONTOS', r':'),           # :
            ('IGUAL', r'=='),              # ==
            ('DIF', r'!='),              # !=
            ('ME_IGUAL', r'<='),              # <=
            ('MA_IGUAL', r'>='),              # >=
            ('OU', r'\|\|'),            # ||
            ('ee', r'&&'),             # &&
            ('ATRIB', r'\='),            # =
            ('MENOR', r'<'),               # <
            ('MAIOR', r'>'),               # >
            ('MAIS', r'\+'),            # +
            ('MENOS', r'-'),            # -
            ('MULT', r'\*'),            # *
            ('DIV', r'\/'),             # /
            ('ID', r'[a-zA-Z]\w*'),     # Identificadores
            ('VALOR_STR', r'"(?:[^"]|"")*"'),     # Identificadores
            ('CONST_INT', r'\d(\d)*'),  # Inteiros
            ('NOVALINHA', r'\n'),         # Nova linha
            ('TAB', r'‚û°Ô∏è'),           # Entrada
            ('ESPACO', r'[ \t]+'),        # Espa√ßo
            ('N_IDEN', r'.'),         # Outros caracteres
        ]

        tokens_join = '|'.join('(?P<%s>%s)' % x for x in regras)
        comeco_linha = 0

        # Lista de sa√≠da para o programa principal.
        token = []
        lexema = []
        linha = []
        coluna = []

        # Analisa o codigo para encontrar os lexemas e os respectivos tokens.
        for m in re.finditer(tokens_join, code):
            tipo_token = m.lastgroup
            lexema_token = m.group(tipo_token)

            if tipo_token == 'NOVALINHA':
                comeco_linha = m.end()
                self.lin_num += 1
            elif tipo_token == 'ESPACO':
                continue
            elif tipo_token == 'N_IDEN':
                raise RuntimeError('%r inesperado na linha %d' % (lexema_token, self.lin_num))
            else:
                    col = m.start() - comeco_linha
                    coluna.append(col)
                    token.append(tipo_token)
                    lexema.append(lexema_token)
                    linha.append(self.lin_num)
                    # Imprime a informa√ß√£o dos tokens encontrados.
                    print('Token = {0}, Lexema = \'{1}\', Linha = {2}, Coluna = {3}'.format(tipo_token, lexema_token, self.lin_num, col))

        return token, lexema, linha, coluna
